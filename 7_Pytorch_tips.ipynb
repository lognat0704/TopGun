{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7_Pytorch_tips.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOzYL6tf28JyQTREkMEuk+M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lognat0704/TopGun/blob/main/7_Pytorch_tips.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cTbkLCwyPiNY"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch \n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Create Directly on the Target Device"
      ],
      "metadata": {
        "id": "Gdo0MRYDQNxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "for _ in range(100):\n",
        "  cpu_tensor = torch.ones((1000,64,64))\n",
        "  gpu_tensor = cpu_tensor.cuda()\n",
        "\n",
        "print('Total time: {:.3f}s'.format(time.time()-start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Wj1nSx9PliZ",
        "outputId": "362ea53d-dd35-48c6-b298-0cd232c59fc6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 12.935s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "for _ in range(100):\n",
        "  gpu_tensor = torch.ones((1000,64,64), device='cuda')\n",
        "\n",
        "print('Total time: {:.3f}s'.format(time.time()-start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg7UoXBdPl5U",
        "outputId": "5ddbd407-bb59-4092-96e1-f54cc8b14e9c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 0.011s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Use Sequential Layers When Possible"
      ],
      "metadata": {
        "id": "YoP1ufGFQUmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExampleModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    input_size = 2\n",
        "    output_size = 3\n",
        "    hidden_size = 16\n",
        "\n",
        "    self.input_layer = nn.Linear(input_size, hidden_size)\n",
        "    self.input_activation = nn.ReLU()\n",
        "\n",
        "    self.mid_layer = nn.Linear(hidden_size, hidden_size)\n",
        "    self.mid_activation = nn.ReLU()\n",
        "\n",
        "    self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    z = self.input_layer(x)\n",
        "    z = self.input_activation(z)\n",
        "    \n",
        "    z = self.mid_layer(z)\n",
        "    z = self.mid_activation(z)\n",
        "    \n",
        "    out = self.output_layer(z)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "9G9dv053QJqM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_model = ExampleModel()\n",
        "print(example_model)\n",
        "print('Output shape:', example_model(torch.ones([100, 2])).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUk65VM3RBHE",
        "outputId": "987ebda2-44fd-4a65-b4b2-3c2cde5a7e30"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExampleModel(\n",
            "  (input_layer): Linear(in_features=2, out_features=16, bias=True)\n",
            "  (input_activation): ReLU()\n",
            "  (mid_layer): Linear(in_features=16, out_features=16, bias=True)\n",
            "  (mid_activation): ReLU()\n",
            "  (output_layer): Linear(in_features=16, out_features=3, bias=True)\n",
            ")\n",
            "Output shape: torch.Size([100, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ExampleSequentialModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    input_size = 2\n",
        "    output_size = 3\n",
        "    hidden_size = 16\n",
        "\n",
        "    self.layers = nn.Sequential(\n",
        "      nn.Linear(input_size, hidden_size),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(hidden_size, hidden_size),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(hidden_size, output_size))\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layers(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "2axsX1hOR5Nh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_seq_model = ExampleSequentialModel()\n",
        "print(example_seq_model)\n",
        "print('Output shape:', example_seq_model(torch.ones([100, 2])).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0Jr6ykZSfkn",
        "outputId": "187ed4e8-e950-4807-ef6e-65d599966e2f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExampleSequentialModel(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=16, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=16, out_features=3, bias=True)\n",
            "  )\n",
            ")\n",
            "Output shape: torch.Size([100, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Don't Make Lists of Layers\n"
      ],
      "metadata": {
        "id": "31seAG8JVl-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BadListModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    input_size = 2\n",
        "    output_size = 3\n",
        "    hidden_size = 16\n",
        "\n",
        "    self.input_layer = nn.Linear(input_size, hidden_size)\n",
        "    self.input_activation = nn.ReLU()\n",
        "\n",
        "    # Fairly common when using residual layers\n",
        "    self.mid_layers = []\n",
        "    for _ in range(5):\n",
        "      self.mid_layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "      self.mid_layers.append(nn.ReLU())\n",
        "\n",
        "    self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    z = self.input_layer(x)\n",
        "    z = self.input_activation(z)\n",
        "    \n",
        "    for layer in self.mid_layers:\n",
        "      z = layer(z)\n",
        "    \n",
        "    out = self.output_layer(z)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "8LX-U6M5SjkT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad_list_model = BadListModel()\n",
        "print('Output shape:', bad_list_model(torch.ones([100, 2])).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeK68R87VnCO",
        "outputId": "f2cd452a-50e1-4a45-d204-7d06950b359c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([100, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bad_list_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5VteH7oWFML",
        "outputId": "0d56d83d-687a-431e-c58f-9601798a5316"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BadListModel(\n",
              "  (input_layer): Linear(in_features=2, out_features=16, bias=True)\n",
              "  (input_activation): ReLU()\n",
              "  (output_layer): Linear(in_features=16, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_input = torch.ones([100, 2], device='cuda')\n",
        "gpu_bad_list_model = bad_list_model.cuda()\n",
        "print('Output shape:', bad_list_model(gpu_input).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "MpKf4IfpWF4H",
        "outputId": "787c4958-fbc1-4fa7-a680-eaed142faaca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e523900f19d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgpu_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgpu_bad_list_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbad_list_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbad_list_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-2df20007fc89>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m       \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CorrectListModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    input_size = 2\n",
        "    output_size = 3\n",
        "    hidden_size = 16\n",
        "\n",
        "    self.input_layer = nn.Linear(input_size, hidden_size)\n",
        "    self.input_activation = nn.ReLU()\n",
        "\n",
        "    # Fairly common when using residual layers\n",
        "    self.mid_layers = []\n",
        "    for _ in range(5):\n",
        "      self.mid_layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "      self.mid_layers.append(nn.ReLU())\n",
        "    self.mid_layers = nn.Sequential(*self.mid_layers)\n",
        "\n",
        "    self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    z = self.input_layer(x)\n",
        "    z = self.input_activation(z)\n",
        "    z = self.mid_layers(z)\n",
        "    out = self.output_layer(z)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "vkI3mMiGWIgq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_list_model = CorrectListModel()\n",
        "correct_list_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBk6KHPTWXsh",
        "outputId": "b85772d3-861a-4606-a6b5-b70ea7222e5c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CorrectListModel(\n",
              "  (input_layer): Linear(in_features=2, out_features=16, bias=True)\n",
              "  (input_activation): ReLU()\n",
              "  (mid_layers): Sequential(\n",
              "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=16, out_features=16, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=16, out_features=16, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Linear(in_features=16, out_features=16, bias=True)\n",
              "    (9): ReLU()\n",
              "  )\n",
              "  (output_layer): Linear(in_features=16, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_input = torch.ones([100, 2], device='cuda')\n",
        "gpu_correct_list_model = correct_list_model.cuda()\n",
        "print('Output shape:', correct_list_model(gpu_input).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_nj3wu2Wa__",
        "outputId": "9937ea54-95ef-4135-9dc1-ab199986c8fe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([100, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Make Use of Distributions\n"
      ],
      "metadata": {
        "id": "j4K7F4_JWk2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "example_model = ExampleModel()\n",
        "input_tensor = torch.rand(5, 2)\n",
        "output = example_model(input_tensor)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIJeQ8d6WisT",
        "outputId": "5cf243ed-3f92-4d45-ccbd-6e960526d035"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.2366, -0.0852, -0.2771],\n",
            "        [ 0.2565, -0.0390, -0.2301],\n",
            "        [ 0.2452, -0.0751, -0.2673],\n",
            "        [ 0.2604, -0.0490, -0.2469],\n",
            "        [ 0.2258, -0.1094, -0.3023]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.distributions import Categorical\n",
        "from torch.distributions.kl import kl_divergence"
      ],
      "metadata": {
        "id": "mrY8ndF1WqlD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist = Categorical(logits=output)\n",
        "dist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpPlJPUJcgiM",
        "outputId": "25621d00-aa53-4d18-ba51-1d9e565436a1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Categorical(logits: torch.Size([5, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get probabilities\n",
        "dist.probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OBwVys7ci8D",
        "outputId": "7a56c8a8-4022-4a4b-8008-14bab05801ff"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4305, 0.3120, 0.2575],\n",
              "        [0.4239, 0.3155, 0.2606],\n",
              "        [0.4301, 0.3122, 0.2576],\n",
              "        [0.4281, 0.3142, 0.2577],\n",
              "        [0.4339, 0.3103, 0.2559]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take samples\n",
        "dist.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEwcToSzckp4",
        "outputId": "ed7c9b33-19e8-4e64-b607-cd18820b1041"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 2, 0, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the KL-Divergence\n",
        "dist_1 = Categorical(logits=output[0])\n",
        "dist_2 = Categorical(logits=output[1])\n",
        "kl_divergence(dist_1, dist_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toFrv3TRcoTp",
        "outputId": "b068c467-b660-46fd-a756-c4f740d6b594"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.7176e-05, grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Use detach() On Long-Term Metrics (detach from gradient)"
      ],
      "metadata": {
        "id": "Lx5Np96Ni6ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "example_model = ExampleModel()\n",
        "data_batches = [torch.rand((10, 2)) for _ in range(5)]\n",
        "criterion = nn.MSELoss(reduce='mean')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo6ZgsxWcs03",
        "outputId": "2d7044ba-ce7e-426a-cd1b-9d643ea47842"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_batches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC8ev0gpi8KW",
        "outputId": "059d4419-6050-4865-c3d8-903b6bd88273"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0.6664, 0.8480],\n",
              "         [0.5517, 0.7500],\n",
              "         [0.3905, 0.4795],\n",
              "         [0.0203, 0.0076],\n",
              "         [0.0342, 0.3239],\n",
              "         [0.0498, 0.4571],\n",
              "         [0.9083, 0.8778],\n",
              "         [0.8400, 0.3951],\n",
              "         [0.0853, 0.3669],\n",
              "         [0.6047, 0.5367]]), tensor([[0.5449, 0.4341],\n",
              "         [0.5255, 0.4515],\n",
              "         [0.8894, 0.5661],\n",
              "         [0.1432, 0.8134],\n",
              "         [0.8033, 0.2864],\n",
              "         [0.4758, 0.6736],\n",
              "         [0.8030, 0.8155],\n",
              "         [0.6492, 0.4487],\n",
              "         [0.6512, 0.3577],\n",
              "         [0.3095, 0.5880]]), tensor([[0.3538, 0.3726],\n",
              "         [0.2964, 0.4321],\n",
              "         [0.4899, 0.4250],\n",
              "         [0.7985, 0.5057],\n",
              "         [0.5507, 0.0346],\n",
              "         [0.0793, 0.7434],\n",
              "         [0.7791, 0.1451],\n",
              "         [0.5251, 0.0108],\n",
              "         [0.0390, 0.6371],\n",
              "         [0.6535, 0.2493]]), tensor([[0.4968, 0.8196],\n",
              "         [0.1775, 0.9922],\n",
              "         [0.9447, 0.2378],\n",
              "         [0.9809, 0.2310],\n",
              "         [0.9258, 0.9089],\n",
              "         [0.7418, 0.6368],\n",
              "         [0.4436, 0.6105],\n",
              "         [0.0852, 0.5228],\n",
              "         [0.7898, 0.2458],\n",
              "         [0.4866, 0.9604]]), tensor([[0.0623, 0.8937],\n",
              "         [0.7984, 0.8327],\n",
              "         [0.7511, 0.6637],\n",
              "         [0.2555, 0.9751],\n",
              "         [0.4643, 0.8673],\n",
              "         [0.8788, 0.2477],\n",
              "         [0.4305, 0.9615],\n",
              "         [0.3681, 0.5023],\n",
              "         [0.4400, 0.3342],\n",
              "         [0.9024, 0.3412]])]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bad Example"
      ],
      "metadata": {
        "id": "I19HGqA7joE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "# Training loop\n",
        "for batch in data_batches:\n",
        "  output = example_model(batch)\n",
        "\n",
        "  target = torch.rand((10, 3))\n",
        "  loss = criterion(output, target)\n",
        "  losses.append(loss)\n",
        "\n",
        "  # Optimization happens here\n",
        "\n",
        "print(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X54L96xsjXmo",
        "outputId": "362876e1-bbfc-4dc0-b217-23235ad7ff37"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor(0.4776, grad_fn=<MseLossBackward0>), tensor(0.5256, grad_fn=<MseLossBackward0>), tensor(0.4602, grad_fn=<MseLossBackward0>), tensor(0.6642, grad_fn=<MseLossBackward0>), tensor(0.5915, grad_fn=<MseLossBackward0>)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Better Example"
      ],
      "metadata": {
        "id": "QrvGYYn5kdmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "# Training loop\n",
        "for batch in data_batches:\n",
        "  output = example_model(batch)\n",
        "\n",
        "  target = torch.rand((10, 3))\n",
        "  loss = criterion(output, target)\n",
        "  losses.append(loss.item()) # Or `loss.detach()`\n",
        "\n",
        "  # Optimization happens here\n",
        "\n",
        "print(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjRiSXoCjpv0",
        "outputId": "9410238a-bc03-4a3d-e14c-bdcd18a18dae"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.649771511554718, 0.5891002416610718, 0.47328534722328186, 0.43510550260543823, 0.42641639709472656]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Trick to Delete a Model from GPU"
      ],
      "metadata": {
        "id": "6LQMs7SclMLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc # garbage collection"
      ],
      "metadata": {
        "id": "Znvgw-trk5No"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_model = ExampleModel().cuda()\n",
        "\n",
        "del example_model\n",
        "\n",
        "gc.collect()\n",
        "# The model will normally stay on the cache until something takes it's place\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "gDZsJGHXlOTj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_model = ExampleModel()\n",
        "\n",
        "# Do training\n",
        "\n",
        "example_model.eval()\n",
        "\n",
        "# Do testing\n",
        "\n",
        "example_model.train()\n",
        "\n",
        "# Do training again"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGq5mJ27lPTS",
        "outputId": "18263d92-705e-4467-d4a6-676bdc1ccab7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExampleModel(\n",
              "  (input_layer): Linear(in_features=2, out_features=16, bias=True)\n",
              "  (input_activation): ReLU()\n",
              "  (mid_layer): Linear(in_features=16, out_features=16, bias=True)\n",
              "  (mid_activation): ReLU()\n",
              "  (output_layer): Linear(in_features=16, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Affects\n",
        "- Dropout\n",
        "- Batch Normalization\n",
        "- RNNs\n",
        "- Lazy Variants\n"
      ],
      "metadata": {
        "id": "ysLH04ADl3Aj"
      }
    }
  ]
}